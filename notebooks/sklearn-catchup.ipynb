{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuwqoiiYjs9fz6JPHHmCto",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enumura1/jp-text-similarity/blob/main/notebooks/sklearn-catchup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9xN3Vgl3xlh",
        "outputId": "0e2a6f70-1d91-48e0-da8a-07580da1fa07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.10/dist-packages (1.0.10)\n",
            "Requirement already satisfied: unidic-lite in /usr/local/lib/python3.10/dist-packages (1.0.8)\n",
            "類似度スコア:\n",
            "スコア: 0.3310 - テキスト: 商品の返品について説明します。返送料は当社負担です。\n",
            "スコア: 0.1592 - テキスト: 商品の交換方法についてご案内いたします。\n",
            "スコア: 0.1262 - テキスト: 支払い方法は、クレジットカード、銀行振込が利用できます。\n",
            "スコア: 0.1592 - テキスト: 配送状況の確認方法をご説明します。\n",
            "\n",
            "最も類似度の高いテキスト:\n",
            "スコア: 0.3310\n",
            "テキスト: 商品の返品について説明します。返送料は当社負担です。\n",
            "\n",
            "各単語のTF-IDFスコア（クエリ）:\n",
            "方法: 0.5380\n",
            "返品: 0.8429\n",
            "\n",
            "形態素解析結果:\n",
            "クエリ: 返品 方法 教え ください\n",
            "リファレンステキスト:\n",
            "商品 返品 つい 説明 し 返送 当社 負担\n",
            "商品 交換 方法 つい 案内 いたし\n",
            "支払い 方法 クレジット カード 銀行 振込 利用 でき\n",
            "配送 状況 確認 方法 説明 し\n"
          ]
        }
      ],
      "source": [
        "!pip install mecab-python3\n",
        "!pip install unidic-lite\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import MeCab\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# MeCabの初期化\n",
        "mecab = MeCab.Tagger()\n",
        "\n",
        "def tokenize_japanese(text):\n",
        "    \"\"\"日本語テキストを形態素解析して単語のリストを返す\"\"\"\n",
        "    node = mecab.parseToNode(text)\n",
        "    words = []\n",
        "    while node:\n",
        "        # 品詞情報を取得\n",
        "        pos = node.feature.split(',')[0]\n",
        "        # 名詞、動詞、形容詞のみを対象とする\n",
        "        if pos in ['名詞', '動詞', '形容詞']:\n",
        "            words.append(node.surface)\n",
        "        node = node.next\n",
        "    return ' '.join(words)\n",
        "\n",
        "# サンプルの日本語テキストデータ\n",
        "reference_texts = [\n",
        "    \"商品の返品について説明します。返送料は当社負担です。\",\n",
        "    \"商品の交換方法についてご案内いたします。\",\n",
        "    \"支払い方法は、クレジットカード、銀行振込が利用できます。\",\n",
        "    \"配送状況の確認方法をご説明します。\",\n",
        "]\n",
        "\n",
        "# テキストの前処理\n",
        "processed_texts = [tokenize_japanese(text) for text in reference_texts]\n",
        "\n",
        "# ユーザーからの質問例\n",
        "query = \"返品の方法を教えてください\"\n",
        "processed_query = tokenize_japanese(query)\n",
        "\n",
        "# TF-IDFベクトル化器の初期化\n",
        "vectorizer = TfidfVectorizer(\n",
        "    # トークナイズは既に行っているので不要\n",
        "    tokenizer=lambda x: x.split(),\n",
        "    analyzer='word'\n",
        ")\n",
        "\n",
        "# リファレンステキストをベクトル化\n",
        "reference_vectors = vectorizer.fit_transform(processed_texts)\n",
        "\n",
        "# クエリをベクトル化\n",
        "query_vector = vectorizer.transform([processed_query])\n",
        "\n",
        "# コサイン類似度の計算\n",
        "similarities = cosine_similarity(query_vector, reference_vectors).flatten()\n",
        "\n",
        "# 結果の表示\n",
        "print(\"類似度スコア:\")\n",
        "for text, score in zip(reference_texts, similarities):\n",
        "    print(f\"スコア: {score:.4f} - テキスト: {text}\")\n",
        "\n",
        "print(\"\\n最も類似度の高いテキスト:\")\n",
        "best_match_index = similarities.argmax()\n",
        "print(f\"スコア: {similarities[best_match_index]:.4f}\")\n",
        "print(f\"テキスト: {reference_texts[best_match_index]}\")\n",
        "\n",
        "# 単語の重要度を確認\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(\"\\n各単語のTF-IDFスコア（クエリ）:\")\n",
        "query_tfidf = query_vector.toarray()[0]\n",
        "for word, score in zip(feature_names, query_tfidf):\n",
        "    if score > 0:\n",
        "        print(f\"{word}: {score:.4f}\")\n",
        "\n",
        "# 参考：形態素解析結果の確認\n",
        "print(\"\\n形態素解析結果:\")\n",
        "print(f\"クエリ: {processed_query}\")\n",
        "print(\"リファレンステキスト:\")\n",
        "for text in processed_texts:\n",
        "    print(text)"
      ]
    }
  ]
}